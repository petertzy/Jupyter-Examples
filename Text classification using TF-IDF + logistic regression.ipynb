{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62787f6-701d-403d-bc41-e57b49a7393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading path: aclImdb/train\n",
      "Subdirectories: ['urls_unsup.txt', 'neg', 'urls_pos.txt', 'unsup', 'urls_neg.txt', 'pos', 'unsupBow.feat', 'labeledBow.feat']\n",
      "Number of files read for category pos: 12500\n",
      "Number of files read for category neg: 12500\n",
      "Validation Accuracy: 0.8736\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Load data\n",
    "def load_reviews(path):\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Path {path} does not exist, please check!\")\n",
    "        return texts, labels\n",
    "    \n",
    "    print(f\"Loading path: {path}\")\n",
    "    print(f\"Subdirectories: {os.listdir(path)}\")\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        label_path = os.path.join(path, label)\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: Subdirectory {label_path} does not exist, skipping this category\")\n",
    "            continue\n",
    "        files = glob.glob(os.path.join(label_path, '*.txt'))\n",
    "        print(f\"Number of files read for category {label}: {len(files)}\")\n",
    "        \n",
    "        for file in files:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                cleaned = clean_text(text)\n",
    "                texts.append(cleaned)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return texts, labels\n",
    "\n",
    "# Main process\n",
    "texts, labels = load_reviews('aclImdb/train')\n",
    "\n",
    "if len(texts) == 0:\n",
    "    print(\"No texts loaded, terminating program.\")\n",
    "else:\n",
    "    # Split train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Feature extraction\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_val_tfidf = vectorizer.transform(X_val)\n",
    "\n",
    "    # Train model\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Validate model\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    print('Validation Accuracy:', accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf323ba-8136-46a6-954b-70316aaca64c",
   "metadata": {},
   "source": [
    "### What the above code does can be summarized as follows:\n",
    "\n",
    "1. **Data Loading and Cleaning**\n",
    "\n",
    "   * It loads all text files from the folders `pos` (positive reviews) and `neg` (negative reviews) inside the directory `aclImdb/train`.\n",
    "   * Each review is cleaned by removing HTML tags, keeping only letters and spaces, and converting all text to lowercase.\n",
    "\n",
    "2. **Data Preparation**\n",
    "\n",
    "   * The cleaned texts are stored in a list called `texts`, and their corresponding labels (1 for positive, 0 for negative) are stored in `labels`.\n",
    "\n",
    "3. **Data Splitting**\n",
    "\n",
    "   * The data is split into training and validation sets, with 80% used for training and 20% for validation.\n",
    "\n",
    "4. **Feature Extraction**\n",
    "\n",
    "   * The text data is transformed into TF-IDF feature vectors using `TfidfVectorizer`, limited to the top 5000 features.\n",
    "\n",
    "5. **Model Training**\n",
    "\n",
    "   * A logistic regression model (`LogisticRegression`) is trained on the training set features and labels.\n",
    "\n",
    "6. **Model Evaluation**\n",
    "\n",
    "   * The model predicts labels for the validation set, and the accuracy is calculated and printed.\n",
    "\n",
    "---\n",
    "\n",
    "**Your output means:**\n",
    "\n",
    "* The program successfully loaded 12,500 positive and 12,500 negative reviews (25,000 total).\n",
    "* The logistic regression model achieved about 87.36% accuracy on the validation set, indicating good performance on the sentiment classification task.\n",
    "\n",
    "In short, this code builds and evaluates a simple sentiment analysis model based on TF-IDF features and logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45824f31-175c-4486-acee-98a4a0f416f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
